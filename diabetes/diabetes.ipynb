{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging; logging.basicConfig(level=logging.INFO)\n",
    "import tensorflow as tf\n",
    "import ltn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  DiabetesPedigreeFunction  Age  Outcome\n",
      "644            3      103             72             30      152  27.6                     0.730   27        0\n",
      "659            3       80             82             31       70  34.2                     1.292   27        1\n",
      "303            5      115             98              0        0  52.9                     0.209   28        1\n",
      "725            4      112             78             40        0  39.4                     0.236   38        0\n",
      "297            0      126             84             29      215  30.7                     0.520   24        0\n",
      "696            3      169             74             19      125  29.9                     0.268   31        1\n",
      "88            15      136             70             32      110  37.1                     0.153   43        1\n",
      "20             3      126             88             41      235  39.3                     0.704   27        0\n",
      "94             2      142             82             18       64  24.7                     0.761   21        0\n",
      "340            1      130             70             13      105  25.9                     0.472   22        0\n",
      "53             8      176             90             34      300  33.7                     0.467   58        1\n",
      "383            1       90             62             18       59  25.1                     1.268   25        0\n",
      "250            9      106             52              0        0  31.2                     0.380   42        0\n",
      "163            2      100             64             23        0  29.7                     0.368   21        0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"diabetes.dat\")\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "df = df.sample(frac=1) #shuffle\n",
    "print(df.head(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']]\n",
    "labels_diabetes = df['Outcome']\n",
    "\n",
    "batch_size=64\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((features[:600], labels_diabetes[:600])).batch(batch_size)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((features[600:], labels_diabetes[600:])).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    \"\"\"Model that returns logits.\"\"\"\n",
    "    def __init__(self, n_classes, hidden_layer_sizes=(16, 16, 8)):\n",
    "        super(MLP, self).__init__()\n",
    "        self.denses = [tf.keras.layers.Dense(s, activation=\"elu\") for s in hidden_layer_sizes]\n",
    "        self.dense_class = tf.keras.layers.Dense(n_classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        for dense in self.denses:\n",
    "            x = dense(x)\n",
    "        return self.dense_class(x)\n",
    "    \n",
    "logits_model = MLP(2)  # Binary classification for diabetes\n",
    "p = ltn.Predicate.FromLogits(logits_model, activation_function=\"sigmoid\", with_class_indexing=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_diabetes = ltn.Constant(1, trainable=False)  # 1: Diabetes\n",
    "class_no_diabetes = ltn.Constant(0, trainable=False) # 0: No diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(p=2), semantics=\"forall\")\n",
    "Exists = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMean(p=2),semantics=\"exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "formula_aggregator = ltn.Wrapper_Formula_Aggregator(ltn.fuzzy_ops.Aggreg_pMeanError(p=2))\n",
    "five = ltn.Constant(5, trainable=False)\n",
    "forty = ltn.Constant(40, trainable=False)\n",
    "thirty = ltn.Constant(30, trainable=False)\n",
    "\n",
    "# Definindo novos predicados\n",
    "is_pregnancies_greater_than_five = ltn.Predicate.Lambda(lambda inputs: tf.greater(inputs[:, 0], five.tensor))\n",
    "is_age_greater_than_forty = ltn.Predicate.Lambda(lambda inputs: tf.greater(inputs[:, 7], forty.tensor))\n",
    "is_bmi_greater_than_thirty = ltn.Predicate.Lambda(lambda inputs: tf.greater(inputs[:, 5], thirty.tensor))\n",
    "\n",
    "@tf.function\n",
    "def axioms(features, labels_diabetes):\n",
    "    \n",
    "    x = ltn.Variable(\"x\", features)\n",
    "    x_diabetes = ltn.Variable(\"x_diabetes\", features[labels_diabetes == 1])\n",
    "    x_no_diabetes = ltn.Variable(\"x_no_diabetes\", features[labels_diabetes == 0])\n",
    "    #x_pregnancies = ltn.Variable(\"x_pregnancies\", features[:, 0]) \n",
    "\n",
    "\n",
    "    axioms = [\n",
    "        Forall(x_no_diabetes, p([x_no_diabetes, class_no_diabetes])),\n",
    "        Forall(x_diabetes, p([x_diabetes, class_diabetes])),\n",
    "        Forall(x, Not(And(p([x, class_diabetes]), p([x, class_no_diabetes])))),\n",
    "        #Forall(x, Implies(is_greater_than_five([x_pregnancies]), p([x, class_diabetes])))\n",
    "    ]\n",
    "    axioms.append(Exists(x, Implies(is_pregnancies_greater_than_five(x), p([x, class_diabetes]))))\n",
    "    axioms.append(Forall(x, Implies(is_age_greater_than_forty(x), p([x, class_diabetes]))))\n",
    "    axioms.append(Forall(x, Implies(is_bmi_greater_than_thirty(x), p([x, class_diabetes]))))\n",
    "    sat_level = formula_aggregator(axioms).tensor\n",
    "    return sat_level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sat level 0.31724\n"
     ]
    }
   ],
   "source": [
    "for features, labels_diabetes in ds_train:\n",
    "    print(\"Initial sat level %.5f\" % axioms(features, labels_diabetes))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'train_sat_kb': tf.keras.metrics.Mean(name='train_sat_kb'),\n",
    "    'test_sat_kb': tf.keras.metrics.Mean(name='test_sat_kb'),\n",
    "    'train_accuracy': tf.keras.metrics.Mean(name=\"train_accuracy\"),\n",
    "    'test_accuracy': tf.keras.metrics.Mean(name=\"test_accuracy\"),\n",
    "    'test_sat_phi1': tf.keras.metrics.Mean(name='test_sat_phi1'),\n",
    "    'test_sat_phi2': tf.keras.metrics.Mean(name='test_sat_phi2'),\n",
    "    #'test_sat_phi3': tf.keras.metrics.Mean(name='test_sat_phi3')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def sat_phi1(features):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    phi1 = Forall(x, Implies(p([x,class_diabetes]),Not(p([x,class_no_diabetes]))),p=10)\n",
    "    return phi1.tensor\n",
    "\n",
    "@tf.function()\n",
    "def sat_phi2(features):\n",
    "    x = ltn.Variable(\"x\",features)\n",
    "    phi2 = Forall(x, Implies(p([x,class_diabetes]),p([x,class_no_diabetes])),p=10)\n",
    "    return phi2.tensor\n",
    "\n",
    "#@tf.function()\n",
    "#def sat_phi3(features):\n",
    "#    x = ltn.Variable(\"x\", features)\n",
    "#    phi3 = Forall(x, Implies(is_age_greater_than_forty(x), p([x, class_diabetes])), p=10)\n",
    "#    return phi3.tensor\n",
    "\n",
    "\n",
    "def multilabel_hamming_loss(y_true, y_pred, threshold=0.5,from_logits=False):\n",
    "    if from_logits:\n",
    "        y_pred = tf.math.sigmoid(y_pred)\n",
    "    y_pred = y_pred > threshold\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    y_pred = tf.cast(y_pred, tf.int32)\n",
    "    nonzero = tf.cast(tf.math.count_nonzero(y_true-y_pred,axis=-1),tf.float32)\n",
    "    return nonzero/y_true.get_shape()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "@tf.function\n",
    "def train_step(features, labels_diabetes):\n",
    "    # sat and update\n",
    "    with tf.GradientTape() as tape:\n",
    "        sat = axioms(features, labels_diabetes)\n",
    "        loss = 1.-sat\n",
    "    gradients = tape.gradient(loss, p.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, p.trainable_variables))\n",
    "    metrics_dict['train_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = logits_model([features])\n",
    "    labels_diabete = (labels_diabetes == 1)\n",
    "    labels_no_diabete = (labels_diabetes == 0)\n",
    "    onehot = tf.stack([labels_diabete, labels_no_diabete],axis=-1)\n",
    "    metrics_dict['train_accuracy'](1-multilabel_hamming_loss(onehot,predictions,from_logits=True))\n",
    "    \n",
    "@tf.function\n",
    "def test_step(features, labels_diabetes):\n",
    "    # sat\n",
    "    sat_kb = axioms(features, labels_diabetes)\n",
    "    metrics_dict['test_sat_kb'](sat_kb)\n",
    "    metrics_dict['test_sat_phi1'](sat_phi1(features))\n",
    "    metrics_dict['test_sat_phi2'](sat_phi2(features))\n",
    "    \n",
    "    # accuracy\n",
    "    predictions = logits_model([features])\n",
    "    labels_no_diabete = (labels_diabetes == 0)\n",
    "    labels_diabete = (labels_diabetes == 1)\n",
    "    onehot = tf.stack([labels_no_diabete, labels_diabete], axis=-1)\n",
    "    metrics_dict['test_accuracy'](1 - multilabel_hamming_loss(onehot, predictions, from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcommons\u001b[39;00m\n\u001b[0;32m      3\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m800\u001b[39m\n\u001b[0;32m      5\u001b[0m commons\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m      6\u001b[0m     EPOCHS,\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mmetrics_dict\u001b[49m,\n\u001b[0;32m      8\u001b[0m     ds_train,\n\u001b[0;32m      9\u001b[0m     ds_test,\n\u001b[0;32m     10\u001b[0m     train_step,\n\u001b[0;32m     11\u001b[0m     test_step,\n\u001b[0;32m     12\u001b[0m     csv_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiabetes_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     track_metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metrics_dict' is not defined"
     ]
    }
   ],
   "source": [
    "import commons\n",
    "\n",
    "EPOCHS = 800\n",
    "\n",
    "commons.train(\n",
    "    EPOCHS,\n",
    "    metrics_dict,\n",
    "    ds_train,\n",
    "    ds_test,\n",
    "    train_step,\n",
    "    test_step,\n",
    "    csv_path=\"diabetes_results.csv\",\n",
    "    track_metrics=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
